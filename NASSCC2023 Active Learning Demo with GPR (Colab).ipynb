{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMDo6STrb66hzCunBphE19l"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["This notebook available at www.github.com/gp0942/NASSSCC23\n","\n","Demo Learning Goals:\n","- Gaussian Processes\n","    - kernels\n","    - prior and posterior distributions\n","- Active Learning\n","    - advantages over random guessing\n","    - accquisition functions\n","        - Upper confidence bound\n","        - probability of improvement\n","        - expected improvement\n","    - exploration vs. exploitation"],"metadata":{"id":"LbvKeifdBJoo"}},{"cell_type":"code","source":["# import required libraries and packages\n","import pandas as pd\n","import numpy as np\n","from sklearn.gaussian_process import GaussianProcessRegressor\n","from sklearn.gaussian_process.kernels import RBF\n","import matplotlib.pyplot as plt\n","from scipy.stats import norm\n","from math import log10, pi\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"VkW_o-k_BEkM","executionInfo":{"status":"ok","timestamp":1691680567502,"user_tz":300,"elapsed":3133,"user":{"displayName":"Gordon Peterson","userId":"14512661585735118002"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["Modeling a simple linear function with Gaussian Process Regression"],"metadata":{"id":"-jdE5zJIBSHf"}},{"cell_type":"code","source":["# define \"ground truth\" function f(x) from 0 < x < 300\n","def f(x):\n","    y = .004*x - 0.5 # simple linear function\n","    return y\n","\n","# create values for x ranging from 0 to some upper limit, and calculate y for those values\n","x = np.linspace(0,300,301)\n","y = f(x)"],"metadata":{"id":"TEZMPnV4BOKz","executionInfo":{"status":"ok","timestamp":1691680593379,"user_tz":300,"elapsed":2,"user":{"displayName":"Gordon Peterson","userId":"14512661585735118002"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# plot f(x)\n","plt.figure(figsize=(8,4)) # create a figure\n","plt.plot(x,y,label='f(x)',color='k') # plot x vs y\n","plt.legend() # add a legend\n","plt.xlabel('x') # change x label to 'x'\n","plt.ylabel('y') # change y label to 'y'\n","plt.show() # show the plot"],"metadata":{"id":"ueei70m5BVPF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_known = 5  # set number of known samples\n","np.random.seed(7) # set random seed for repeatable results\n","\n","# define known x and y values\n","x_known = np.random.randint(x.min(),x.max(),n_known) # sample n_known random points from x\n","y_known = f(x_known) # calculate y for the sampled points\n","\n","# plot f(x) with known data points\n","plt.figure(figsize=(8,4))\n","plt.plot(x,y,label='f(x)',color='k')\n","plt.scatter(x_known,y_known,label='Known',color='k') # plot the known points on the f(x) line\n","plt.legend()\n","plt.xlabel('x')\n","plt.ylabel('y')\n","plt.show()"],"metadata":{"id":"CwGic1qJBWeS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# define kernel with Radial Basis Function and Gaussian Process Regressor model\n","# https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.RBF.html\n","# https://distill.pub/2019/visual-exploration-gaussian-processes/\n","kernel = RBF() # define the kernel for the model\n","gp = GaussianProcessRegressor(kernel=kernel,n_restarts_optimizer=40) # instantiate the GPR model"],"metadata":{"id":"Vy5z1lBHBdxA","executionInfo":{"status":"ok","timestamp":1691680632800,"user_tz":300,"elapsed":205,"user":{"displayName":"Gordon Peterson","userId":"14512661585735118002"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# predict the y values for the full range of x\n","# our model is untrained, so there is no basis for any predictions\n","# this is called our \"prior\" distribution\n","y_pred, sigma = gp.predict(x.reshape(-1,1), return_std = True) # predict the y values and standard dev's based on our untrained model\n","\n","# plot f(x) with prior distribution\n","plt.figure(figsize=(8,4))\n","plt.plot(x,y,label='f(x)',color='k')\n","plt.xlabel('x')\n","plt.ylabel('y')\n","plt.scatter(x_known,y_known,color='k')\n","plt.plot(x,y_pred, color = 'red', label = 'GPR', linestyle = '--') # plot the fit line from the GPR model\n","plt.fill_between(x,y_pred - sigma, y_pred + sigma, alpha = 0.1, color = 'red') # shade in one standard deviation around the fit\n","plt.legend()\n","plt.show()"],"metadata":{"id":"xLV7euZYBe2h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train model on the known data\n","gp.fit(x_known.reshape(-1,1),y_known)\n","\n","# re-predict the distribution after training, this is our \"posterior\" distribution\n","y_pred, sigma = gp.predict(x.reshape(-1,1), return_std = True)\n","plt.figure(figsize=(8,4))\n","plt.plot(x,y,label='f(x)',color='k')\n","plt.scatter(x_known,y_known,color='k')\n","plt.plot(x,y_pred, color = 'red', label = 'GPR', linestyle = '--')\n","plt.fill_between(x,y_pred - sigma, y_pred + sigma, alpha = 0.1, color = 'red')\n","plt.legend()\n","plt.xlabel('x')\n","plt.ylabel('y')\n","plt.show()"],"metadata":{"id":"eefiyoIgBf_q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["What about more complex functions?"],"metadata":{"id":"QY4On_-_BiE8"}},{"cell_type":"code","source":["# define \"ground truth\" function f(x) from 0 < x < 300\n","def f(x): # multiple options given, leave desired function uncommented or make up your own!\n","    y = -np.sin(x/30) + 1/8*np.cos(x**(1/1.4)) + 3.5*np.exp((-(x-250)**2)/(170)) + .5*np.exp((-(x-150)**2)/(250)) + 1*np.exp((-(x-60)**2)/(3000)) + 1.3*np.exp((-(x-85)**2)/(70)) # a few summed gaussians\n","    #y = np.sin(x/7) - np.cos(x**(1/1.4)) + 10**(-3.5)*(x-40)**2  # complex periodic function\n","    return y\n","\n","y = f(x)"],"metadata":{"id":"LMVD00bNBhGQ","executionInfo":{"status":"ok","timestamp":1691680655150,"user_tz":300,"elapsed":1,"user":{"displayName":"Gordon Peterson","userId":"14512661585735118002"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# plot f(x)\n","plt.figure(figsize=(8,4))\n","plt.plot(x,y,label='f(x)',color='k')\n","plt.legend()\n","plt.xlabel('x')\n","plt.ylabel('y')\n","plt.show()"],"metadata":{"id":"aZr0K_xfBkV5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_known = 5  # set number of known samples\n","np.random.seed(7) # set random seed for repeatable results\n","\n","# define known x and y values\n","x_known = np.random.randint(x.min(),x.max(),n_known)\n","y_known = f(x_known)\n","\n","# plot f(x) with known data points\n","plt.figure(figsize=(8,4))\n","plt.plot(x,y,label='f(x)',color='k')\n","plt.scatter(x_known,y_known,label='Known',color='k')\n","plt.legend()\n","plt.xlabel('x')\n","plt.ylabel('y')\n","plt.show()"],"metadata":{"id":"VxiI7_wDBlSk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# define kernel with Radial Basis Function and Gaussian Process Regressor model\n","# https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.RBF.html\n","# https://distill.pub/2019/visual-exploration-gaussian-processes/\n","kernel = RBF()\n","gp = GaussianProcessRegressor(kernel=kernel,n_restarts_optimizer=40)"],"metadata":{"id":"Jn8RCwICBmbr","executionInfo":{"status":"ok","timestamp":1691680668257,"user_tz":300,"elapsed":192,"user":{"displayName":"Gordon Peterson","userId":"14512661585735118002"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# predict the y values for the full range of x\n","# our model is untrained, so there is no basis for any predictions\n","# this is called our \"prior\" distribution\n","y_pred, sigma = gp.predict(x.reshape(-1,1), return_std = True)\n","\n","# plot f(x) with prior distribution\n","plt.figure(figsize=(8,4))\n","plt.plot(x,y,label='f(x)',color='k')\n","plt.xlabel('x')\n","plt.ylabel('y')\n","plt.scatter(x_known,y_known,color='k')\n","plt.plot(x,y_pred, color = 'red', label = 'GPR', linestyle = '--')\n","plt.fill_between(x,y_pred - sigma, y_pred + sigma, alpha = 0.1, color = 'red')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"_5GMYqOlBngD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train model on the known data\n","gp.fit(x_known.reshape(-1,1),y_known)\n","\n","# re-predict the distribution after training, this is our \"posterior\" distribution\n","y_pred, sigma = gp.predict(x.reshape(-1,1), return_std = True)\n","plt.figure(figsize=(8,4))\n","plt.plot(x,y,label='f(x)',color='k')\n","plt.scatter(x_known,y_known,color='k')\n","plt.plot(x,y_pred, color = 'red', label = 'GPR', linestyle = '--')\n","plt.fill_between(x,y_pred - sigma, y_pred + sigma, alpha = 0.1, color = 'red')\n","plt.legend()\n","plt.xlabel('x')\n","plt.ylabel('y')\n","plt.show()"],"metadata":{"id":"GpA-wjCSBofS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["How does the model improve if we were to randomly guess new measurement points?"],"metadata":{"id":"roI_ojs5Bq7a"}},{"cell_type":"code","source":["# set the number of loops to run, adding a new random point each time\n","n_loops = 15\n","\n","# set random seed\n","np.random.seed(7)\n","\n","# determine the initial RMSE value and instantiate an RMSE list\n","rmse = [np.sqrt((y_pred-y)**2).mean()]\n","\n","# initialize list for tracking max value\n","y_max = []\n","\n","# create copies of the original x_known and y_known so we can save them for later\n","x_known2, y_known2 = x_known, y_known\n","\n","# set dimensions fo our figure\n","fig, ax = plt.subplots(2,1)\n","fig.set_figwidth(8)\n","fig.set_figheight(6)\n","\n","# plot current GPR fit\n","ax[0].set_title(f'Model after {n_loops} Random Learning cycles')\n","ax[0].plot(x,y_pred, label = f'GPR 0', linestyle = '--',alpha=1) # plot the initial model (before new points are added)\n","\n","for loop in range(n_loops): # add one new random sample for each new loop\n","    x_new = np.array([np.random.choice(x[[x_sample not in x_known2 for x_sample in x]])]) # add a new sample randomly among numbers not already in x_known\n","    y_new = f(x_new) # calculate the y value for the new x point\n","    x_known2 = np.concatenate((x_known2,x_new)) # add the new x point to the list of known values\n","    y_known2 = f(x_known2) # calculate all the values for the known x points\n","\n","    # re-train model on the new full data set and predict a new fit\n","    gp.fit(x_known2.reshape(-1,1),y_known2)\n","    y_pred,sigma = gp.predict(x.reshape(-1,1),return_std = True)\n","\n","    # plot new GPR fit\n","    ax[0].plot(x,y_pred, label = f'GPR {loop+1}', linestyle = '--',alpha=1,zorder=loop)\n","#    ax[0].legend()\n","\n","    # calculate RMSE and max Y of model\n","    rmse.append(np.sqrt((y_pred-y)**2).mean())\n","    y_max.append(y_known2.max())\n","\n","# plot f(x), the newest training point, and standard deviation for last model trained\n","ax[0].plot(x,y,color='k',zorder=0)\n","ax[0].scatter(x_known2,y_known2,color='k')\n","ax[0].fill_between(x,y_pred - sigma, y_pred + sigma, alpha = 0.1, color = 'red',zorder=0)\n","#ax[0].legend(loc='lower right')  # uncomment if you want to see the labels for each line\n","if n_loops>0:\n","    ax[0].scatter(x_new,y_new,color='r',zorder=10)\n","\n","# plot the RMSE\n","ax[1].scatter(range(len(rmse)),rmse,color='k')\n","ax[1].plot(rmse,color='k')\n","ax[1].set_ylabel('RMSE')\n","ax[1].set_xlabel('Cycle')\n","ax[1].set_xlim(-0.1,len(rmse)-0.9)\n","ax[1].text(x=0.95,y=0.8,s=f'Final RMSE = {round(rmse[-1],3)}',transform=ax[1].transAxes,ha='right')\n","\n","# plot y max\n","ax1 = plt.twinx()\n","ax1.scatter(range(len(y_max)),y_max,color='r')\n","ax1.plot(y_max,color='r')\n","ax1.set_ylabel('Maximum Y Found')\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"7O3YIhJlBpxd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Active Learning: Acquisition Functions"],"metadata":{"id":"1vf36yhSBwOk"}},{"cell_type":"code","source":["# re-train the model on just the originally known data, and re-predict the values for that\n","gp.fit(x_known.reshape(-1,1),y_known)\n","y_pred,sigma = gp.predict(x.reshape(-1,1),return_std=True)"],"metadata":{"id":"QfFKzwg4Bsop","executionInfo":{"status":"ok","timestamp":1691680718032,"user_tz":300,"elapsed":196,"user":{"displayName":"Gordon Peterson","userId":"14512661585735118002"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["### Upper Confidence Bound (UCB)"],"metadata":{"id":"Iww7pQJHB0Az"}},{"cell_type":"markdown","source":["UCB[i] = y[i] + lambda * sigma[i]"],"metadata":{"id":"wLuBob-kB7eT"}},{"cell_type":"code","source":["# plot f(x) and known data points\n","plt.figure(figsize=(8,4))\n","plt.plot(x,y,label='f(x)',color='k')\n","plt.scatter(x_known,y_known,color='k')\n","plt.xlabel('x')\n","plt.ylabel('y')\n","\n","# plot UCB with large lambda (favoring exploration)\n","lbda = 3\n","ucb = y_pred + lbda*sigma\n","plt.plot(x,ucb,color = 'brown',label = f'\\u03bb = {lbda}',linestyle='dotted')\n","plt.scatter(x=ucb.argmax(),y=ucb.max(),color='red',facecolors='none')\n","\n","# plot UCB with moderate lambda (middle ground)\n","lbda = 1\n","ucb = y_pred + lbda*sigma\n","plt.plot(x,ucb,color = 'darkgoldenrod',label = f'\\u03bb = {lbda}',linestyle='dotted')\n","plt.scatter(x=ucb.argmax(),y=ucb.max(),color='red',facecolors='none')\n","\n","# plot UCB with small lambda (favoring exploitation)\n","lbda = .2\n","ucb = y_pred + lbda*sigma\n","plt.plot(x,ucb,color = 'gold',label = f'\\u03bb = {lbda}',linestyle='dotted')\n","plt.scatter(x=ucb.argmax(),y=ucb.max(),color='red',facecolors='none')\n","\n","plt.legend()\n","plt.show()"],"metadata":{"id":"7V6Spb5nBzjO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Probability of Improvement (PI)"],"metadata":{"id":"bbdN8fTTCDwM"}},{"cell_type":"markdown","source":["Probability distribution function: f(x) = exp((-x^2)/2)/sqrt(2*pi)"],"metadata":{"id":"vxPCaegaCKx2"}},{"cell_type":"code","source":["# generate probability density\n","x_p = np.linspace(-3,3,100)\n","y_p = [np.exp(-(xp**2)/2)/(2*pi)**(1/2) for xp in x_p]\n","\n","# plot probability density function\n","plt.figure(figsize=(8,4))\n","plt.plot(x_p,y_p,label='Prob. Dens.',color='k')\n","\n","# plot cumulative distribution function\n","plt.plot(x_p,norm.cdf(x_p),label='Cum. Dist',color='gray',linestyle='dashed')\n","plt.xlabel('\\u03C3')\n","plt.ylabel('Probability')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"x5jt_PZFCB9E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["z-score: zz[i] = (y[i] - ymax)/sigma[i] - epsilon\n","\n","PI[i] = CDF(zz[i])"],"metadata":{"id":"zdyFVzLwCVuP"}},{"cell_type":"code","source":["# plot f(x) and known data points\n","plt.figure(figsize=(8,4))\n","plt.plot(x,y,label='f(x)',color='k')\n","plt.plot(x,y_pred, color = 'red', label = 'Post', linestyle = '--')\n","plt.fill_between(x,y_pred - sigma, y_pred + sigma, alpha = 0.1, color = 'red')\n","plt.scatter(x_known,y_known,color='k')\n","plt.xlabel('x')\n","plt.ylabel('y')\n","ax2 = plt.twinx()\n","\n","# determine the GPR best predicted value from the training set\n","y_best = gp.predict(x_known.reshape(-1,1)).max()\n","\n","def PoI(y_pred,sigma,y_best,epsilon,scale,loc):\n","    PI = np.empty(y_pred.size,dtype=float)\n","    for i in range(0,y_pred.size):\n","        if sigma[i] > 1e-4:\n","            zz = (y_pred[i]-y_best-epsilon)/sigma[i]\n","            PI[i] = norm.cdf(zz)\n","        else:\n","            PI[i] = 0.0\n","    return PI\n","\n","# plot PI with large epsilon value (favoring exploration)\n","epsilon = 5\n","zz = (y_pred-y_best-epsilon)/sigma\n","PI = PoI(y_pred,sigma,y_best,epsilon,scale=zz.std(),loc=zz.mean())\n","PI = PI/PI.max() # scale for visibility\n","ax2.plot(x,PI,color='navy',linestyle='dotted',label=f'\\u03b5 = {epsilon}')\n","ax2.scatter(PI.argmax(),PI.max(),color='r',facecolors='none')\n","\n","# plot PI with moderate epsilon value (middle ground)\n","epsilon = 1\n","zz = (y_pred-y_best-epsilon)/sigma\n","PI = PoI(y_pred,sigma,y_best,epsilon,scale=zz.std(),loc=zz.mean())\n","PI = PI/PI.max() # scale for visibility\n","ax2.plot(x,PI,color='blue',linestyle='dotted',label=f'\\u03b5 = {epsilon}')\n","ax2.scatter(PI.argmax(),PI.max(),color='r',facecolors='none')\n","\n","# plot PI with small epsilon value (favoring exploitation)\n","epsilon = 0\n","zz = (y_pred-y_best-epsilon)/sigma\n","PI = PoI(y_pred,sigma,y_best,epsilon,scale=zz.std(),loc=zz.mean())\n","PI = PI/PI.max() # scale for visibilty\n","ax2.plot(x,PI,color='skyblue',linestyle='dotted',label=f'\\u03b5 = {epsilon}')\n","ax2.scatter(PI.argmax(),PI.max(),color='r',facecolors='none')\n","ax2.set_ylabel('Prob. Imp. (scaled)')\n","ax2.set_ylim(0,PI.max()*1.2)\n","\n","plt.legend(loc='lower left')\n","plt.show()"],"metadata":{"id":"x_Gn5tMxCTtS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Expected Improvement (EI)"],"metadata":{"id":"L8xrvel9CjzX"}},{"cell_type":"markdown","source":["z-score: zz[i] = (y[i] - ymax)/sigma[i] - epsilon\n","\n","\n","EI[i] = (y[i] - ymax - epsilon) * CDF(zz[i]) + sigma[i] * PDF(zz[i])"],"metadata":{"id":"AMbTlp9-CnVK"}},{"cell_type":"code","source":["# plot f(x) and known data points\n","plt.figure(figsize=(8,4))\n","plt.plot(x,y,label='f(x)',color='k')\n","plt.plot(x,y_pred, color = 'red', label = 'Post', linestyle = '--')\n","plt.fill_between(x,y_pred - sigma, y_pred + sigma, alpha = 0.1, color = 'red')\n","plt.scatter(x_known,y_known,color='k')\n","plt.xlabel('x')\n","plt.ylabel('y')\n","\n","\n","# determine the GPR best predicted value from the training set\n","y_best = gp.predict(x_known.reshape(-1,1)).max()\n","\n","def expI(y_pred,sigma,y_best,epsilon):\n","    EI = np.empty(y_pred.size,dtype=float)\n","    for i in range(0,y_pred.size):\n","        if sigma[i] > 1e-4:\n","            zz = (y_pred[i]-y_best-epsilon)/sigma[i]\n","            EI[i] = (y_pred[i]-y_best-epsilon)*norm.cdf(zz,scale=1)+sigma[i]*norm.pdf(zz,scale=1)\n","        else:\n","            EI[i] = 0.0\n","    return EI\n","\n","# plot PI with large epsilon value (favoring exploration)\n","epsilon = 2\n","ax2 = plt.twinx()\n","EI = expI(y_pred,sigma,y_best,epsilon)\n","EI = EI/EI.max() # scale for visibility\n","ax2.plot(x,EI,color='navy',linestyle='dotted',label=f'\\u03b5 = {epsilon}')\n","ax2.scatter(EI.argmax(),EI.max(),color='r',facecolors='none')\n","\n","# plot PI with moderate epsilon value (middle ground)\n","epsilon = .5\n","EI = expI(y_pred,sigma,y_best,epsilon)\n","EI = EI/EI.max() # scale for visibility\n","ax2.plot(x,EI,color='blue',linestyle='dotted',label=f'\\u03b5 = {epsilon}')\n","ax2.scatter(EI.argmax(),EI.max(),color='r',facecolors='none')\n","\n","# plot PI with small epsilon value (favoring exploitation)\n","epsilon = 0\n","EI = expI(y_pred,sigma,y_best,epsilon)\n","EI = EI/EI.max() # scale for visibility\n","ax2.plot(x,EI,color='skyblue',linestyle='dotted',label=f'\\u03b5 = {epsilon}')\n","ax2.scatter(EI.argmax(),EI.max(),color='r',facecolors='none')\n","ax2.set_ylabel('Expected Imp. (scaled)')\n","ax2.set_ylim(0,EI.max()*1.2)\n","\n","plt.legend(loc='lower left')\n","plt.show()"],"metadata":{"id":"CThPrd8VCik3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, we will iteratively add data new data points based on our Expected Improvement function, rather than randomly (active learning). How does this compare to our previous result?"],"metadata":{"id":"i8jFkN-LC74t"}},{"cell_type":"code","source":["# set how many loops to train\n","n_loops = 10\n","epsilon = .1\n","\n","# set random seed\n","np.random.seed(7)\n","\n","# reset the model to original conditions (in case you ran this cell already)\n","x_known2, y_known2 = x_known, y_known\n","gp.fit(x_known.reshape(-1,1),y_known)\n","y_pred,sigma = gp.predict(x.reshape(-1,1),return_std=True)\n","\n","# set up the plotting\n","fig, ax = plt.subplots(3,1)\n","fig.set_figwidth(8)\n","fig.set_figheight(9)\n","\n","# calculate initial RMSE\n","rmse = [np.sqrt((y_pred-y)**2).mean()]\n","\n","# plot current GPR fit\n","ax[0].set_title(f'Model after {n_loops} Active Learning cycles')\n","ax[0].plot(x,y_pred, label = f'GPR 0', linestyle = '--',alpha=1)\n","\n","# initialize list to track maximum y known\n","y_max = []\n","\n","for loop in range(n_loops):\n","\n","    # determine the most valuable point by expected improvement\n","    EI = expI(y_pred,sigma,y_best,epsilon)\n","    x_new = np.array([EI.argmax()])\n","    y_new = y[[EI.argmax()]]\n","\n","    # add the new data point to the known data\n","    x_known2 = np.concatenate((x_known2,x_new))\n","    y_known2 = np.concatenate((y_known2,y_new))\n","\n","    # re-train model on the new full data set and predict a new fit\n","    gp.fit(x_known2.reshape(-1,1),y_known2)\n","    y_pred,sigma = gp.predict(x.reshape(-1,1),return_std = True)\n","\n","    # determine the GPR best predicted value from the new training set\n","    y_best = gp.predict(x_known2.reshape(-1,1)).max()\n","\n","    # plot new GPR fit\n","    ax[0].plot(x,y_pred, label = f'GPR {loop+1}', linestyle = '--',alpha=1,zorder=loop)\n","\n","    # calculate RMSE of model\n","    rmse.append(np.sqrt((y_pred-y)**2).mean())\n","    y_max.append(y_known2.max())\n","\n","# plot f(x), the newest training point, and standard deviation for last model trained\n","ax[0].plot(x,y,color='k',zorder=0)\n","ax[0].scatter(x_known2,y_known2,color='k')\n","ax[0].fill_between(x,y_pred - sigma, y_pred + sigma, alpha = 0.1, color = 'red',zorder=0)\n","#ax[0].legend(loc='lower right')\n","if n_loops>0:\n","    ax[0].scatter(x_new,y_new,color='r',zorder=10)\n","\n","#determine the most valuable point for the new model by expected improvement\n","EI = expI(y_pred,sigma,y_best,epsilon)\n","\n","# plot the expected improvement graph highlighting the next training point\n","ax[1].bar(x,EI,color='black')\n","ax[1].scatter(EI.argmax(),EI.max(),color='red',facecolors='none',label='Best')\n","ax[1].set_ylabel('Exp. Impr.')\n","ax[1].set_xlabel('x')\n","ax[1].legend()\n","\n","# plot the RMSE\n","ax[2].scatter(range(len(rmse)),rmse,color='k')\n","ax[2].plot(rmse,color='k')\n","ax[2].set_ylabel('RMSE')\n","ax[2].set_xlabel('Cycle')\n","ax[2].set_xlim(-0.1,len(rmse)-0.9)\n","ax[2].text(x=.9,y=0.8,s=f'RMSE = {round(rmse[-1],3)}',transform=ax[2].transAxes,ha='right')\n","\n","# plot y max\n","ax1 = plt.twinx()\n","ax1.scatter(range(len(y_max)),y_max,color='r')\n","ax1.plot(y_max,color='r')\n","ax1.set_ylabel('Maximum Y Found')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"fTCQZ4WPC6w_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ThL5koUfDE01"},"execution_count":null,"outputs":[]}]}