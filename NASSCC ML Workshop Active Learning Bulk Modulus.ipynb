{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a154392",
   "metadata": {},
   "source": [
    "### Active Learning for Predicting Voigt-Reuss-Hill Bulk Modulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b8470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python libraries (rerun cell if get a 'duecredit' error)\n",
    "from mp_api.client import MPRester\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from flatten_dict import flatten\n",
    "from matminer.featurizers.composition import ElementProperty\n",
    "from matminer.featurizers.conversions import StrToComposition\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import forestci as fci\n",
    "import warnings\n",
    "\n",
    "#suppress warnings from fci\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# function to determine the expected improvement\n",
    "def expI(y_post,sigma_post,y_best,epsilon,scale,loc):\n",
    "    EI = np.empty(y_post.size,dtype=float)\n",
    "    for i in range(0,y_post.size):\n",
    "        if sigma_post[i] > 1e-3: # values where sigma is 0 or very small will give errors\n",
    "            zz = (y_post[i]-y_best-epsilon)/sigma_post[i]\n",
    "            EI[i] = (y_post[i]-y_best-epsilon)*norm.cdf(zz,scale=scale,loc=loc)+sigma_post[i]*norm.pdf(zz,scale=scale,loc=loc)\n",
    "        else:\n",
    "            EI[i] = 0.0\n",
    "    return EI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8fb056",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# retrieve data from MP on all stable compounds (~2 min)\n",
    "with MPRester('MP API CODE') as mpr: # << ADD MPI API code here!!!\n",
    "    docs = mpr.summary.search(\n",
    "                              is_stable = [True],                    \n",
    "                              fields = ['material_id','elements','composition_reduced',\n",
    "                                        'formula_pretty','band_gap','structure','k_vrh','g_vrh'\n",
    "                                       ]\n",
    "                             )\n",
    "\n",
    "# flatten dictionary\n",
    "flattened = [{\n",
    "    k: v for k, v in flatten(doc.dict(), reducer=\"dot\").items() if k != \"fields_not_requested\"\n",
    "} for doc in docs]\n",
    "\n",
    "# reformat data into a dataframe object\n",
    "df = pd.DataFrame.from_records(flattened)\n",
    "    \n",
    "# drop elemental He, Ne, Ar\n",
    "df = df.drop(df[df['composition_reduced.He']>0].index)\n",
    "df = df.drop(df[df['composition_reduced.Ne']>0].index)\n",
    "df = df.drop(df[df['composition_reduced.Ar']>0].index)\n",
    "\n",
    "# drop compounds that do not have bulk modulus data\n",
    "df = df.dropna(subset='k_vrh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9831f0",
   "metadata": {},
   "source": [
    "Featurize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63476b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define MagPie featurization (~5 min)\n",
    "featurizer = ElementProperty.from_preset('magpie')\n",
    "str_comp = StrToComposition(target_col_id='pmg_comp')\n",
    "\n",
    "# featurize data set\n",
    "df = str_comp.featurize_dataframe(df,col_id='formula_pretty')\n",
    "features = featurizer.featurize_dataframe(df,col_id='pmg_comp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa87dcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the unneeded columns from the feature dataframe\n",
    "features = features[features.columns[97:]]\n",
    "\n",
    "# reindex the data and feature dataframes\n",
    "df = df.reset_index(drop=True)\n",
    "features = features.reset_index(drop=True)\n",
    "\n",
    "# uncomment to save dataframes as Microsoft Excel xlsx files to import in the future\n",
    "#features.to_excel('Kvrh_features.xlsx',index=False)\n",
    "#df.to_excel('Kvrh.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bceffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to load feature and data dataframes from Excel files\n",
    "#features = pd.read_excel('Kvrh_features.xlsx')\n",
    "#df = pd.read_excel('Kvrh.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b044cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the prediction quality of a RFR model\n",
    "n_samp = 400      # number of initial known samples\n",
    "rfr = RandomForestRegressor(n_estimators=100) # define parameters of Random Forest Regression model\n",
    "np.random.seed(2) # random seed for reproducible results\n",
    "mae = []         # initialize list for MAE\n",
    "r2 = []           # initialize list for R2\n",
    "\n",
    "# create an initial training dataset with n_samp random samples\n",
    "df_train_rfr = df.sample(n_samp).copy()\n",
    "df_remain_rfr = df.drop(df_train_rfr.index).copy()\n",
    "features_train_rfr = features.iloc[df_train_rfr.index].copy()\n",
    "features_remain_rfr = features.drop(df_train_rfr.index).copy()\n",
    "\n",
    "# fit the RFR model\n",
    "rfr.fit(features_train_rfr,df_train_rfr['k_vrh'])\n",
    "y_pred_rfr = rfr.predict(features_remain_rfr)\n",
    "sigma_pred_rfr = fci.random_forest_error(rfr,np.array(features_train_rfr),np.array(features_remain_rfr))\n",
    "\n",
    "# create the parity plot for the final iteration\n",
    "mae.append(mean_absolute_error(df_remain_rfr['k_vrh'],y_pred_rfr))\n",
    "r2.append(r2_score(df_remain_rfr['k_vrh'],y_pred_rfr))\n",
    "fig,ax = plt.subplots(figsize=(5,5))\n",
    "plt.scatter(df_remain_rfr['k_vrh'],y_pred_rfr,alpha=0.1,color='k',\n",
    "#            s=sigma_pred_rfr\n",
    "           )\n",
    "plt.plot([0,y_pred_rfr.max()],[0,y_pred_rfr.max()],linestyle='--',lw=3)\n",
    "plt.xlim(0,y_pred_rfr.max())\n",
    "plt.ylim(0,y_pred_rfr.max())\n",
    "plt.xlabel('MP Bulk Modulus')\n",
    "plt.ylabel('GPR Predicted Bulk Modulus')\n",
    "plt.text(x=.05,y=.95,s=f'MAE = {round(mae[-1],3)}',transform=ax.transAxes)\n",
    "plt.text(x=.05,y=.91,s=f'R2 = {round(r2[-1],3)}',transform=ax.transAxes)\n",
    "plt.text(x=.05,y=.87,s=f'Best = {round(y_pred_rfr.max(),3)}',transform=ax.transAxes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56e0b2c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# iteratively train a model to predict k_vrh with active learning\n",
    "n_samp = 400      # number of initial known samples\n",
    "n_loops = 10       # number of active learning iterations (1 loop means no added compounds)\n",
    "n_compounds = 50  # number of new compounds to measure in each iteration\n",
    "epsilon = 0       # exploration/exploitation parameter (increase to favor exploration)\n",
    "rfr = RandomForestRegressor(n_estimators=100) # define parameters of Random Forest Regression model\n",
    "np.random.seed(8) # random seed for reproducible results\n",
    "mae = []         # initialize list for MAE\n",
    "r2 = []           # initialize list for R2\n",
    "y_best_list = []  # initialize list for Best prediction\n",
    "plot_EI = False    # turn on plotting of best EI compounds\n",
    "\n",
    "# create an initial training dataset with n_samp random samples\n",
    "df_train_rfr = df.sample(n_samp).copy()\n",
    "df_remain_rfr = df.drop(df_train_rfr.index).copy()\n",
    "features_train_rfr = features.iloc[df_train_rfr.index].copy()\n",
    "features_remain_rfr = features.drop(df_train_rfr.index).copy()\n",
    "\n",
    "for loop in range(n_loops):\n",
    "    # print the number of data points in the training/prediction sets\n",
    "    print('Training size:',len(features_train_rfr),', Prediction size:',len(features_remain_rfr))\n",
    "    \n",
    "    # fit the RFR model\n",
    "    rfr.fit(features_train_rfr,df_train_rfr['k_vrh'])\n",
    "    y_pred_rfr = rfr.predict(features_remain_rfr)\n",
    "    sigma_pred_rfr = fci.random_forest_error(rfr,np.array(features_train_rfr),np.array(features_remain_rfr))\n",
    "\n",
    "    # determine the maximum predicted k_vrh in the training set\n",
    "    y_best = rfr.predict(features_train_rfr).max()\n",
    "\n",
    "    # determine the set of zz (to be able to scale and locate distribution for CDF/PDF)\n",
    "    zz = (y_pred_rfr-y_best)/sigma_pred_rfr\n",
    "\n",
    "    # calculate Expected Improvement\n",
    "    EI = expI(y_pred_rfr,sigma_pred_rfr,y_best,epsilon,scale=zz.std(),loc=zz.mean())\n",
    "\n",
    "    # plot EI\n",
    "    EI_df = pd.DataFrame(EI,columns=['EI'])\n",
    "    EI_df_top = EI_df.sort_values(by='EI',ascending=False).head(n_compounds)\n",
    "    if plot_EI == True:\n",
    "        plt.figure(figsize=(6,3))\n",
    "        plt.scatter(range(len(EI)),EI,alpha=0.03,color='k')\n",
    "        plt.scatter(EI_df_top.index,EI_df_top,color='r',facecolors='none')\n",
    "        plt.xlabel('Sample Number')\n",
    "        plt.ylabel('Expected Improvement')\n",
    "        comp_names = df_remain_rfr.iloc[EI_df_top.index]['formula_pretty']\n",
    "        for i, comp in enumerate(comp_names):\n",
    "            plt.annotate(comp,(EI_df_top.index[i],float(EI_df_top['EI'].loc[EI_df_top.index[i]])))\n",
    "        plt.show()\n",
    "    \n",
    "    # create the parity plot for the final iteration\n",
    "    mae.append(mean_absolute_error(df_remain_rfr['k_vrh'],y_pred_rfr))\n",
    "    r2.append(r2_score(df_remain_rfr['k_vrh'],y_pred_rfr))\n",
    "    y_best_list.append(y_best)\n",
    "    if loop == n_loops-1: # only print the parity plot for the final iteration\n",
    "        fig,ax = plt.subplots(figsize=(5,5))\n",
    "        plt.scatter(df_remain_rfr['k_vrh'],y_pred_rfr,alpha=0.1,color='k')\n",
    "                    #,s=sigma_pred_rfr)\n",
    "        plt.plot([0,y_pred_rfr.max()],[0,y_pred_rfr.max()],linestyle='--',lw=3)\n",
    "        plt.xlim(0,y_pred_rfr.max())\n",
    "        plt.ylim(0,y_pred_rfr.max())\n",
    "        plt.xlabel('MP Bulk Modulus')\n",
    "        plt.ylabel('GPR Predicted Bulk Modulus')\n",
    "        plt.text(x=.05,y=.95,s=f'MAE = {round(mae[-1],3)}',transform=ax.transAxes)\n",
    "        plt.text(x=.05,y=.91,s=f'R2 = {round(r2[-1],3)}',transform=ax.transAxes)\n",
    "        plt.text(x=.05,y=.87,s=f'Best = {round(y_pred_rfr.max(),3)}',transform=ax.transAxes)\n",
    "        plt.show()\n",
    "\n",
    "    # add top {n_compounds} compounds to training dataset, remove them from the remain dataset\n",
    "    features_train_rfr = pd.concat([features_train_rfr,features_remain_rfr.iloc[EI_df.sort_values(by='EI',ascending=False).head(n_compounds).index]])\n",
    "    features_remain_rfr = features_remain_rfr.drop(features_remain_rfr.iloc[EI_df.sort_values(by='EI',ascending=False).head(n_compounds).index].index)\n",
    "    df_train_rfr = pd.concat([df_train_rfr,df_remain_rfr.iloc[EI_df.sort_values(by='EI',ascending=False).head(n_compounds).index]])\n",
    "    df_remain_rfr = df_remain_rfr.drop(df_remain_rfr.iloc[EI_df.sort_values(by='EI',ascending=False).head(n_compounds).index].index)\n",
    "\n",
    "# print plots of the trends in MAE, R2, and Best predicted sample over iterations\n",
    "fig,ax = plt.subplots(1,2,figsize=(8,4))\n",
    "ax[0].scatter(range(len(mae)),mae,color = 'k',label='MAE')\n",
    "ax[0].plot(mae,color='k')\n",
    "ax[0].legend(loc='center left')\n",
    "ax1 = plt.twinx(ax=ax[0])\n",
    "ax1.scatter(range(len(r2)),r2,color='r',label='R2')\n",
    "ax1.plot(r2,color='r')\n",
    "ax1.legend(loc='center right')\n",
    "ax[0].set_xlabel('Iteration')\n",
    "ax[1].plot(y_best_list)\n",
    "ax[1].scatter(range(len(y_best_list)),y_best_list)\n",
    "ax[1].set_ylabel('Best Predicted')\n",
    "ax[1].set_xlabel('Iteration')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6c5a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare our active learning approach to a random sampling approach\n",
    "n_samp = 400      # number of initial known samples\n",
    "n_loops = 10       # number of active learning iterations (1 loop means no added compounds)\n",
    "n_compounds = 50  # number of new compounds to measure in each iteration\n",
    "rfr = RandomForestRegressor(n_estimators=100) # define parameters of Random Forest Regression model\n",
    "np.random.seed(8) # random seed for reproducible results\n",
    "mae = []         # initialize list for MAE\n",
    "r2 = []           # initialize list for R2\n",
    "y_best_list = []  # initialize list for Best prediction\n",
    "\n",
    "# create an initial training dataset with n_samp random samples\n",
    "df_train_rfr = df.sample(n_samp).copy()\n",
    "df_remain_rfr = df.drop(df_train_rfr.index).copy()\n",
    "features_train_rfr = features.iloc[df_train_rfr.index].copy()\n",
    "features_remain_rfr = features.drop(df_train_rfr.index).copy()\n",
    "\n",
    "for loop in range(n_loops):\n",
    "    # print the number of data points in the training/prediction sets\n",
    "    print('Training size:',len(features_train_rfr),', Prediction size:',len(features_remain_rfr))\n",
    "    \n",
    "    # fit the RFR model\n",
    "    rfr.fit(features_train_rfr,df_train_rfr['k_vrh'])\n",
    "    y_pred_rfr = rfr.predict(features_remain_rfr)\n",
    "    sigma_pred_rfr = fci.random_forest_error(rfr,np.array(features_train_rfr),np.array(features_remain_rfr))\n",
    "\n",
    "    # determine the maximum predicted k_vrh in the training set\n",
    "    y_best = rfr.predict(features_train_rfr).max()\n",
    "    \n",
    "    # create the parity plot for the final iteration\n",
    "    mae.append(mean_absolute_error(df_remain_rfr['k_vrh'],y_pred_rfr))\n",
    "    r2.append(r2_score(df_remain_rfr['k_vrh'],y_pred_rfr))\n",
    "    y_best_list.append(y_best)\n",
    "    if loop == n_loops-1: # only print the parity plot for the final iteration\n",
    "        fig,ax = plt.subplots(figsize=(5,5))\n",
    "        plt.scatter(df_remain_rfr['k_vrh'],y_pred_rfr,alpha=0.1,color='k')\n",
    "                    #,s=sigma_pred_rfr)\n",
    "        plt.plot([0,y_pred_rfr.max()],[0,y_pred_rfr.max()],linestyle='--',lw=3)\n",
    "        plt.xlim(0,y_pred_rfr.max())\n",
    "        plt.ylim(0,y_pred_rfr.max())\n",
    "        plt.xlabel('MP Bulk Modulus')\n",
    "        plt.ylabel('GPR Predicted Bulk Modulus')\n",
    "        plt.text(x=.05,y=.95,s=f'MAE = {round(mae[-1],3)}',transform=ax.transAxes)\n",
    "        plt.text(x=.05,y=.91,s=f'R2 = {round(r2[-1],3)}',transform=ax.transAxes)\n",
    "        plt.text(x=.05,y=.87,s=f'Best = {round(y_pred_rfr.max(),3)}',transform=ax.transAxes)\n",
    "        plt.show()\n",
    "\n",
    "    # add top {n_compounds} compounds to training dataset, remove them from the remain dataset\n",
    "    new_features = features_remain_rfr.sample(n_compounds)\n",
    "    features_remain_rfr = features_remain_rfr.drop(new_features.index)\n",
    "    features_train_rfr = pd.concat([features_train_rfr,new_features])\n",
    "    df_train_rfr = pd.concat([df_train_rfr,df_remain_rfr.loc[new_features.index]])\n",
    "    df_remain_rfr = df_remain_rfr.drop(new_features.index)\n",
    "\n",
    "# print plots of the trends in MAE, R2, and Best predicted sample over iterations\n",
    "fig,ax = plt.subplots(1,2,figsize=(8,4))\n",
    "ax[0].scatter(range(len(mae)),mae,color = 'k',label='MAE')\n",
    "ax[0].plot(mae,color='k')\n",
    "ax[0].legend(loc='center left')\n",
    "ax1 = plt.twinx(ax=ax[0])\n",
    "ax1.scatter(range(len(r2)),r2,color='r',label='R2')\n",
    "ax1.plot(r2,color='r')\n",
    "ax1.legend(loc='center right')\n",
    "ax[0].set_xlabel('Iteration')\n",
    "ax[1].plot(y_best_list)\n",
    "ax[1].scatter(range(len(y_best_list)),y_best_list)\n",
    "ax[1].set_ylabel('Best Predicted')\n",
    "ax[1].set_xlabel('Iteration')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
